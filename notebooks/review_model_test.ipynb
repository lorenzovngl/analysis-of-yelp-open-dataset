{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review Classification with Yelp Open Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains a code which you can execute to make a rating prediction on a review of your choice. The model used is a neural network built with Tensorflow and trained on the data of the [Yelp Open Dataset](https://www.yelp.com/dataset); the text of the reviews is processed with some NLP techniques explained [here](https://www.youtube.com/watch?v=fNxaJsNG3-s&list=PLQY2H8rRoyvzDbLUZkbudP-MFQZwNmU4S)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/lorenzovngl/analysis-of-yelp-open-dataset/blob/master/notebooks/review_model_test.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for word embedding\n",
    "\n",
    "vocab_size = 10000\n",
    "embedding_dim = 128\n",
    "max_length = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download train sentences\n",
    "\n",
    "!wget --no-check-certificate \\\n",
    "    https://raw.githubusercontent.com/lorenzovngl/analysis-of-yelp-open-dataset/master/notebooks/models/train_sentences.json \\\n",
    "    -O /tmp/train_sentences.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training sentences to setup the tokenizer\n",
    "\n",
    "import json\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "with open(\"/tmp/train_sentences.json\", 'r') as f:\n",
    "    train_sentences = json.load(f)\n",
    "f.close()\n",
    "\n",
    "tokenizer = Tokenizer(num_words=vocab_size, oov_token=\"OOV\")\n",
    "tokenizer.fit_on_texts(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries needed\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download weight for the model\n",
    "\n",
    "!wget --no-check-certificate \\\n",
    "    https://raw.githubusercontent.com/lorenzovngl/analysis-of-yelp-open-dataset/master/notebooks/models/model_weights_run2.h5 \\\n",
    "    -O /tmp/model_weights_run2.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the model\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dropout(0.4),\n",
    "    tf.keras.layers.Dense(5, activation='softmax')\n",
    "])\n",
    "\n",
    "model.load_weights('/tmp/model_weights_run2.h5')\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace sentences with ones of which you want to know prediction (in English only)\n",
    "\n",
    "sentences = [\n",
    "    \"Horrible, this is a bad place. Disgusting.\",\n",
    "    \"I recommend to all to have a dinner here.\",\n",
    "    \"This is the best place I have ever been!\",\n",
    "    \"Not so good, not so bad.\",\n",
    "    \"Not so bad, not so good.\"\n",
    "]\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(sentences)\n",
    "padded = pad_sequences(sequences, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the predicion and print results\n",
    "\n",
    "result = model.predict(padded)\n",
    "\n",
    "for i in range(len(result)):    \n",
    "    fig, axes = plt.subplots(1, 1)\n",
    "    fig.suptitle('\"%s\" rating prediction' % sentences[i], fontsize=16)\n",
    "\n",
    "    axes.bar([k+1 for k in range(5)], [result[i][j] for j in range(5)])\n",
    "    axes.set_ylabel('Probability')\n",
    "    axes.yaxis.set_major_formatter(FuncFormatter(lambda y, _: '{:.0%}'.format(y)))\n",
    "    axes.set_xlabel('Stars')\n",
    "    axes.set_ylim(0, 1)\n",
    "    for h, v in enumerate(result[i]):\n",
    "        axes.text(h+1, v+0.05, (\"%.2f%%\" % float(v*100)), horizontalalignment='center')\n",
    "\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.18rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
